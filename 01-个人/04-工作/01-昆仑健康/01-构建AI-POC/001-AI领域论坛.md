---
createTime: 2025-03-19
link: https://www.bilibili.com/video/BV1JJ4m1L7HS
---
2024-03-27 在博鳌亚洲论坛年会——《AIGC改变世界》分论坛上，《人工智能：现代方法》作者、加州大学伯克利分校计算机科学系教授斯图尔特·罗素表示，当前的人工智能是错误的方向。中国工程院院士、清华大学讲席教授、清华大学智能产业研究院（AIR）院长张亚勤表示，不改变现在的算法，AI是不可持续的。


> [!note]
> **问题**：现在的人工智能算成功吗？
> **罗素**：现在的人工智能方向是错误的

我认为 GPT4 语言模型已经非常优秀了。但是我相信还有很大的技术缺口，我不认为简单的扩展，能让这个模型越来越大，训练更多的数据就能弥合这个差距，这个差距来自系统中无法收到的训练数据。虽然他现在的文本能力已经比一般人阅读量大数十万倍。

但是还有一些基本问题。这是因为模型的构建方法，是电路，电路没有办法用语言表达，非常复杂的事情。
我们可以预测他需要更多的训练数据，当前我们所扩展的大语言模型就好像是黑匣子，他是不透明的，我们不能够满足目标是否精准，这是错误的方向，我们不应该朝这个方向走，我们不能够自信的做出陈述，说明这个系统能够实现什么。


**曾毅（中国科学院自动化研究所研究员，联合国人工智能高层顾问专家）**：

首先我说想的是，我们现在的人工智能，他确实只是一个看是一个智能的信息处理工具，最开始设计的愿景并不是这样的，但看到人工智能作为一个学科出现的时候，当他谈到人类智能学习或者智能的方方面面，都能够被精确地描述。以至于一个计算系统能够模拟他的话，我们认为这样的系统叫做人工智能。行为上接近人类的一些表现。但是在一些关键的、人类从不犯错的领域或者案例中，不停的在犯人不犯错的错误，所以这就说明现在的人工智能他还只是一个看似智能，但是还没有真正智能能力的系统。

现在的人工智能是一个看似智能的信息处理系统。但是他不具备真正的理解能力。
举一个例子，我没有女朋友了，我的家人也都不喜欢我，我的领导要把我开除掉，这个时候我怎么办？
最开始的AI就会告诉你，那你就去死，因为绝大多数具备这样特征的人都死了。但是人工智能他不理解什么叫死亡，什么叫生命。他只会告诉你具有统计显著性的答案。但是他家要知道，人类的价值观，在任何场景下并不一定能够穷举的。看似智能的处理必须改变一种方式，所以我们一定要追求真正意义上的人工智能。我认为这是人工智能的技术研究以及未来人类演化都需要共同计划的方向。

我认为未来人工智能应该机制驱动的人工智能，他从自然演化中去学习人类智能的结构和机制，对于行为的模拟，在行为上导致他跟人类接近，但是他仍然会犯人类不犯的错误，而且人类不犯错误是很难进行穷举的。因为他们在结构和机制上跟人类智慧有很大差别。即使人类只能做到 60% 正确率，机器能做到 99%，另外剩下的1%的时候，他还是很多人不会犯的错误。你仍然觉得这样的智能部署到社会中，这个代价是不能够接受的。

我们现在人工智能赋予他的所谓价值观校准实际上就是符号之间建立了一些映射，那不是真正的理解能力。


> [!note]
> **问题**：发展人工智能正确的方式是什么
> **罗素**：什么才算真正的人工智能

假如不是训练更大规模的电路，另一种方向是什么？过几年可能就会发现，下一代GPT诞生，或者下一代什么模型的诞生，他们训练的模型是之前的数十倍，终会有那个时候，就是数据终结的时候，宇宙中已经没有更多的数据了。假设他没有带来真正的AGI，那么我们别无选择，必须去寻找不同的方向。

希望不需要大量的例子去训练，从十个例子、百个例子就可以完成。
第二他们的运行原则我们可以理解，分析每一个步骤是干什么的，去检查他是否正确，了解每一个要素的原理。从一个复杂的算数运算得出结果，那样运用公式套用或者人之常情那样。把他组成复杂系统，我们就理解了这个复杂的系统。今天的AI恰恰是违反了这个思路，我们不了解如何运作，不了解原理，没办法设计工具，只是让其增长。

实际上两三万年前，驯化了狗和马，让他们保暖，让他们狩猎给他们食物。我们并不了解原理，也不理解如何共存，所以我认为下一个里程碑将会是我们能够展示出来我们可以使AI系统学习，并且向人类一样产生产品。同时内部运行机制是我们所理解的。这是我们努力的方向。

**张亚勤 （工程院院士，清华大学智能产业AIR院长）**

我认为未来五年左右，算力还会增长，生物学数据和物理学数据信息大几个数量级。算力还会增长，算力还会使用现有框架，这也是一个问题，就完全使用算力，不改进算法，没有新框架的话是不可持续下去的。
算力带来的更多电力、排放都是一个大数目，2030年，算力要占到 10%左右。